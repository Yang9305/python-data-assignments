{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "写在最前面 , 思路是:\n",
    "1. 先通过浏览器的方式跳转到需要抓取信息的页面.\n",
    "2. 按F12键, 找出需要的信息在哪些标签上面, 这些标签有什么特征. 需要大概了解 HTML/CSS/JavaScript 的原理\n",
    "3. 找到这些标签和标签特有的属性之后, 可以考虑通过python脚本.\n",
    "4. python脚本完成的主要功能是模拟\"爬虫\", 抓取目标页面的HTML信息, 然后通过python的第三方库BeautifulSoup完成对html文本的解析. 获取到目标数据\n",
    "5. 对目标数据进行进一步处理. 变成结构化的数据, 保存在csv中. 但这里不局限csv. 能够用来记录文本或表格的电子文件格式, 只要python能找到第三方库\n",
    ", 应该都可以写\n",
    "'''\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    " \n",
    "def get_url(url):\n",
    "    '''\n",
    "    url: 输入参数, 是请求的网页的地址\n",
    "    headers: 请求头信息, 用来模拟浏览器发起的请求\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        headers = {\n",
    "            'Connection': 'Keep-Alive',\n",
    "            'Accept': 'text/html, application/xhtml+xml, */*',\n",
    "            'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko'\n",
    "        }\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        \n",
    "        return r.text\n",
    "    except:\n",
    "        print('wrong!!!!!!!!!!!!!')\n",
    " \n",
    " \n",
    "def singer_url(url):\n",
    "    '''\n",
    "    1. 通过url获取到页面的html文本\n",
    "    2. 使用第三方库BeautifulSoup解析html的DOM(document object model 文档对象模型), 获取到需要的节点数据.\n",
    "    3. 此处为, 含有class: u-cover u-cover-5 css类属性修饰的div标签.\n",
    "    4. re使用正则表达式(regular express)过滤出artist的名字,以及该歌手在网易云主页的超链接\n",
    "    '''\n",
    "    #只抓取前10位的歌手\n",
    "    \n",
    "    html = get_url(url)\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    top_10 = soup.find_all('div',attrs = {'class':'u-cover u-cover-5'})\n",
    "    singers = []\n",
    "    \n",
    "    for i in top_10:\n",
    "        \n",
    "        singers.append(re.findall(r'.*?<a class=\"msk\" href=\"(/artist\\?id=\\d+)\" title=\"(.*?)的音乐\"></a>.*?',str(i))[0])#问号有问题\n",
    "        #解析的代码和源代码的顺序不同，在用正则表达式的时候要注意       \n",
    "    song_info(singers)\n",
    "\n",
    "    \n",
    "def song_info(singers):\n",
    "    '''\n",
    "    1. 获取每一个歌手个人主页的html信息\n",
    "    2. 通过BeautifulSoup解析出需要的部分包括, 歌名, 歌曲播放地址, 专辑\n",
    "    '''\n",
    "    \n",
    "    url = 'http://music.163.com'\n",
    "    \n",
    "    for singer in singers:\n",
    "        try:\n",
    "            new_url = url + str(singer[0])\n",
    "            songs = get_url(new_url)\n",
    "            soup = BeautifulSoup(songs,'html.parser')\n",
    " \n",
    "            Info = soup.find_all('textarea',attrs = {'style':'display:none;'})[0]\n",
    "            songs_url_and_name = soup.find_all('ul',attrs = {'class':'f-hide'})[0]\n",
    "            \n",
    "            datas = []\n",
    "            data1 = re.findall(r'\"album\".*?\"name\":\"(.*?)\".*?',str(Info.text))\n",
    "            data2 = re.findall(r'.*?<li><a href=\"(/song\\?id=\\d+)\">(.*?)</a></li>.*?',str(songs_url_and_name))\n",
    " \n",
    "            for i in range(len(data2)):\n",
    "                datas.append([data2[i][1],data1[i],'http://music.163.com/#'+ str(data2[i][0])])\n",
    "            save_excel(singer,datas)\n",
    "        except:\n",
    "            continue\n",
    " \n",
    " \n",
    "\n",
    "def save_excel(singer,datas):\n",
    "    '''\n",
    "    将歌手和歌手对应的歌名,专辑,歌曲链接. 通过第三方库csv, 把数据写到csv格式文件中.\n",
    "    '''\n",
    "    \n",
    "    heads = ['歌曲名称','专辑','歌曲链接']\n",
    "     \n",
    "    with open(singer[1] + '.csv', \"w\") as f:\n",
    "\n",
    "        writer = csv.writer(f)\n",
    "        for row in datas:\n",
    "#             print(row)\n",
    "            writer.writerows([[row[0],row[1],row[2]]])\n",
    "        f.close()\n",
    "    print('OK！')\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    url = 'http://music.163.com/discover/artist/cat?id=1001'#华语男歌手页面\n",
    "    singer_url(url)\n",
    "\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
